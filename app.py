#Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡ Ù‡Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø´Ø¯Ù‡
import streamlit as st  # Ø¨Ø±Ø§ÛŒ Ø³Ø§Ø®Øª Ø±Ø§Ø¨Ø· Ú©Ø§Ø±Ø¨Ø±ÛŒ ÙˆØ¨
import pandas as pd     # Ø¨Ø±Ø§ÛŒ Ø³Ø§Ø®Øª Ùˆ Ù†Ù…Ø§ÛŒØ´ Ø¬Ø¯ÙˆÙ„â€ŒÙ‡Ø§
from langchain_community.document_loaders import WebBaseLoader  # Ø¨Ø±Ø§ÛŒ Ø®ÙˆØ§Ù†Ø¯Ù† Ù…ØªÙ† Ø§Ø² ÙˆØ¨â€ŒØ³Ø§ÛŒØªâ€ŒÙ‡Ø§
from langchain_text_splitters import RecursiveCharacterTextSplitter # Ø¨Ø±Ø§ÛŒ ØªÚ©Ù‡â€ŒØªÚ©Ù‡ Ú©Ø±Ø¯Ù† Ù…ØªÙ†â€ŒÙ‡Ø§ÛŒ Ø·ÙˆÙ„Ø§Ù†ÛŒ
from langchain_huggingface import HuggingFaceEmbeddings # Ø¨Ø±Ø§ÛŒ ØªØ¨Ø¯ÛŒÙ„ Ù…ØªÙ† Ø¨Ù‡ Ø¹Ø¯Ø¯ (Ø¨Ø±Ø¯Ø§Ø±)
from langchain_community.vectorstores import Chroma # Ø¯ÛŒØªØ§Ø¨ÛŒØ³ Ø¨Ø±Ø¯Ø§Ø±ÛŒ Ø¨Ø±Ø§ÛŒ Ø°Ø®ÛŒØ±Ù‡ Ù…ØªÙ†â€ŒÙ‡Ø§
from langchain_community.llms import Ollama # Ø¨Ø±Ø§ÛŒ Ø§Ø±ØªØ¨Ø§Ø· Ø¨Ø§ Ù…Ø¯Ù„ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Llama3
import os       # Ø¨Ø±Ø§ÛŒ Ú©Ø§Ø± Ø¨Ø§ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø³ÛŒØ³ØªÙ… Ø¹Ø§Ù…Ù„
import shutil   #Ù¾Ø§Ú© Ú©Ø±Ø¯Ù† Ø¯ÛŒØªØ§Ø¨ÛŒØ³ Ù‚Ø¯ÛŒÙ…ÛŒ

#ØªÙ†Ø¸ÛŒÙ…Ø§Øª ØµÙØ­Ù‡ Ø§ØµÙ„ÛŒ
st.set_page_config(page_title="Ø¯Ø³ØªÛŒØ§Ø± ÙÛŒÙ„Ù…", layout="wide", page_icon="ğŸ¬")

#CSS
st.markdown("""
<style>
    /* ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ú©Ù„ÛŒ ØµÙØ­Ù‡ */
    .stApp {
        direction: rtl;
        text-align: right;
        font-family: 'Vazirmatn', sans-serif;
    }
    
    /* ØªÛŒØªØ± ÙˆØ³Ø·â€ŒÚ†ÛŒÙ† */
    .main-header {
        text-align: center; 
        color: #ff4b4b;
        font-size: 3em;
        font-weight: bold;
        margin-bottom: 20px;
        text-shadow: 2px 2px 4px #000000;
    }
    
    /* Ø¨Ø§Ú©Ø³ Ø¬ÙˆØ§Ø¨ */
    .answer-box {
        background-color: #262730;
        padding: 20px;
        border-radius: 10px;
        border-right: 5px solid #ff4b4b;
        margin-top: 20px;
    }

    /* --- ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø§Ø¬Ø¨Ø§Ø±ÛŒ Ø¨Ø±Ø§ÛŒ Ø³Ø§ÛŒØ¯Ø¨Ø§Ø± Ùˆ ÙˆØ±ÙˆØ¯ÛŒâ€ŒÙ‡Ø§ --- */
    
    /* Ø±Ø§Ø³Øªâ€ŒÚ†ÛŒÙ† Ú©Ø±Ø¯Ù† Ù…ØªÙ† Ø¯Ø§Ø®Ù„ ÙˆØ±ÙˆØ¯ÛŒâ€ŒÙ‡Ø§ Ùˆ Text Area */
    .stTextInput input, .stTextArea textarea {
        direction: rtl;
        text-align: right;
    }
    
    /* Ø±Ø§Ø³Øªâ€ŒÚ†ÛŒÙ† Ú©Ø±Ø¯Ù† Ù„ÛŒØ¨Ù„ (ØªÛŒØªØ±) Ø¨Ø§Ù„Ø§ÛŒ ÙˆØ±ÙˆØ¯ÛŒâ€ŒÙ‡Ø§ */
    .stTextArea label, .stTextInput label {
        width: 100%;
        text-align: right !important;
        display: flex;
        justify-content: flex-end; /* Ù‡Ù„ Ø¯Ø§Ø¯Ù† Ù…ØªÙ† Ø¨Ù‡ Ø³Ù…Øª Ø±Ø§Ø³Øª */
    }
    
    /* Ø±Ø§Ø³Øªâ€ŒÚ†ÛŒÙ† Ú©Ø±Ø¯Ù† Ú©Ù„ Ø³Ø§ÛŒØ¯Ø¨Ø§Ø± */
    [data-testid="stSidebar"] {
        direction: rtl;
        text-align: right;
    }

    /* --- ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø§Ø¬Ø¨Ø§Ø±ÛŒ Ø¨Ø±Ø§ÛŒ Ø¬Ø¯ÙˆÙ„â€ŒÙ‡Ø§ --- */
    div[data-testid="stTable"] table {
        direction: rtl;
        width: 100%;
    }
    /* Ø±Ø§Ø³Øªâ€ŒÚ†ÛŒÙ† Ú©Ø±Ø¯Ù† ØªÛŒØªØ± Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ */
    div[data-testid="stTable"] th {
        text-align: right !important;
        direction: rtl;
    }
    /* Ø±Ø§Ø³Øªâ€ŒÚ†ÛŒÙ† Ú©Ø±Ø¯Ù† Ù…Ø­ØªÙˆØ§ÛŒ Ø³Ù„ÙˆÙ„â€ŒÙ‡Ø§ */
    div[data-testid="stTable"] td {
        text-align: right !important;
        direction: rtl;
    }
</style>
""", unsafe_allow_html=True)

#ØªØ­Ù„ÛŒÙ„ Ùˆ Ø§Ù…Ø¨Ø¯ÛŒÙ†Ú¯ Ù„ÛŒÙ†Ú© Ù‡Ø§
EMBEDDING_MODEL_NAME = "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
PERSIST_DIRECTORY = "./chroma_db"

@st.cache_resource
def load_embedding_model():
    return HuggingFaceEmbeddings(model_name=EMBEDDING_MODEL_NAME)

def process_websites(urls):
    if os.path.exists(PERSIST_DIRECTORY):
        try:
            shutil.rmtree(PERSIST_DIRECTORY)
        except:
            pass

    with st.spinner(' Ø¯Ø± Ø­Ø§Ù„ Ù…Ø·Ø§Ù„Ø¹Ù‡...'):
        loader = WebBaseLoader(urls)
        data = loader.load()
        
        text_splitter = RecursiveCharacterTextSplitter(chunk_size=800, chunk_overlap=100)
        all_splits = text_splitter.split_documents(data)
        
        embedding_model = load_embedding_model()
        vector_db = Chroma.from_documents(
            documents=all_splits, 
            embedding=embedding_model, 
            persist_directory=PERSIST_DIRECTORY
        )
        return vector_db, len(all_splits)

def get_rag_response(query, vector_db):
    llm = Ollama(model="llama3")
    retriever = vector_db.as_retriever(search_kwargs={"k": 8})
    relevant_docs = retriever.invoke(query)
    return relevant_docs, llm

#Ø±Ø§Ø¨Ø· Ú©Ø§Ø±Ø¨Ø±ÛŒ
st.markdown('<h1 class="main-header">ğŸ¬ Ø¯Ø³ØªÛŒØ§Ø± Ù‡ÙˆØ´Ù…Ù†Ø¯ Ù†Ù‚Ø¯ Ùˆ Ø¨Ø±Ø±Ø³ÛŒ ÙÛŒÙ„Ù…</h1>', unsafe_allow_html=True)

with st.sidebar:
    st.header("ğŸŒ Ù…Ù†Ø§Ø¨Ø¹ Ø§Ø·Ù„Ø§Ø¹Ø§ØªÛŒ")
    input_urls = st.text_area(
        "Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§ÛŒ ÙˆØ¨â€ŒØ³Ø§ÛŒØªâ€ŒÙ‡Ø§ (Ù‡Ø± Ø®Ø· ÛŒÚ© Ù„ÛŒÙ†Ú©)", 
        value="https://fa.wikipedia.org/wiki/Ù¾Ø¯Ø±Ø®ÙˆØ§Ù†Ø¯Ù‡\nhttps://fa.wikipedia.org/wiki/Ø´ÙˆØ§Ù„ÛŒÙ‡_ØªØ§Ø±ÛŒÚ©ÛŒ_(ÙÛŒÙ„Ù…)",
        height=150
    )
    urls = [url.strip() for url in input_urls.split('\n') if url.strip()]
    
    if st.button("ğŸš€ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…Ù†Ø§Ø¨Ø¹", use_container_width=True):
        if urls:
            try:
                vector_db, count = process_websites(urls)
                st.session_state['db_ready'] = True
                st.success(f"âœ… {count} Ø¨Ø®Ø´ Ø§Ø² Ù…ØªÙ† ÙÛŒÙ„Ù…â€ŒÙ‡Ø§ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.")
            except Exception as e:
                st.error(f"Ø®Ø·Ø§: {e}")
        else:
            st.warning("Ù„Ø·ÙØ§Ù‹ Ù„ÛŒÙ†Ú© ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯.")

if st.session_state.get('db_ready'):
    embedding_model = load_embedding_model()
    vector_db = Chroma(persist_directory=PERSIST_DIRECTORY, embedding_function=embedding_model)
    
    query = st.text_input("ğŸ¿ Ø³ÙˆØ§Ù„ Ø³ÛŒÙ†Ù…Ø§ÛŒÛŒ Ø®ÙˆØ¯ Ø±Ø§ Ø¨Ù¾Ø±Ø³ÛŒØ¯:", placeholder="Ù…Ø«Ù„Ø§Ù‹: Ù…ÙˆØ¶ÙˆØ¹ Ø§ØµÙ„ÛŒ ÙÛŒÙ„Ù… Ù¾Ø¯Ø±Ø®ÙˆØ§Ù†Ø¯Ù‡ Ú†ÛŒØ³ØªØŸ")
    
    if query:
        docs, llm = get_rag_response(query, vector_db)
        
        with st.spinner("ğŸ¤– Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ø¯Ø± Ø­Ø§Ù„ Ù†ÙˆØ´ØªÙ† Ù†Ù‚Ø¯..."):
            context_text = "\n\n".join([doc.page_content for doc in docs])
            
#Ù¾Ø±Ø§Ù…Øª Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ
            prompt = f"""
            You are a helpful AI assistant that speaks ONLY Persian (Farsi).
            
            CRITICAL INSTRUCTIONS:
            1. Answer the user's question strictly in PERSIAN language.
            2. Do NOT write any English sentences.
            3. Start your answer directly in Persian text.
            4. Use the provided Context to answer.
            
            Context:
            {context_text}
            
            User Question: {query}
            """
            
            response = llm.invoke(prompt)
            
#Ù†Ø­ÙˆÙ‡ Ù†Ù…Ø§ÛŒØ´ Ø¬ÙˆØ§Ø¨
            st.markdown(f"""
            <div class="answer-box" style="direction: rtl; text-align: right;">
                <h3 style="margin-bottom: 15px;">ğŸ’¡ Ù¾Ø§Ø³Ø® Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ:</h3>
                <div dir="auto" style="font-size: 1.1em; line-height: 1.8; text-align: start;">
                    {response}
                </div>
            </div>
            """, unsafe_allow_html=True)

        st.markdown("<br>", unsafe_allow_html=True)
        
        # Ø¬Ø¯ÙˆÙ„ Ù…Ù†Ø§Ø¨Ø¹
        with st.expander("ğŸ“š Ù…Ø´Ø§Ù‡Ø¯Ù‡ Ù…ØªÙ†â€ŒÙ‡Ø§ÛŒ Ù¾ÛŒØ¯Ø§ Ø´Ø¯Ù‡ Ø¯Ø± Ù…Ù†Ø§Ø¨Ø¹ (Ø¨Ø±Ø§ÛŒ Ø¨Ø±Ø±Ø³ÛŒ Ø¯Ù‚ÛŒÙ‚â€ŒØªØ±)"):
            table_data = []
            for doc in docs:
                table_data.append({
                    "Ù…Ù†Ø¨Ø¹": doc.metadata.get('source', 'Ù†Ø§Ù…Ø´Ø®Øµ'),
                    "Ø¨Ø®Ø´ÛŒ Ø§Ø² Ù…ØªÙ†": doc.page_content[:300] + "...",
                })
                
                st.table(pd.DataFrame(table_data))

else:
    st.info("ğŸ‘ˆ Ø¨Ø±Ø§ÛŒ Ø´Ø±ÙˆØ¹ØŒ Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§ Ø±Ø§ Ø¯Ø± Ù…Ù†ÙˆÛŒ Ø³Ù…Øª Ø±Ø§Ø³Øª ÙˆØ§Ø±Ø¯ Ú©Ø±Ø¯Ù‡ Ùˆ Ø¯Ú©Ù…Ù‡ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø±Ø§ Ø¨Ø²Ù†ÛŒØ¯.")